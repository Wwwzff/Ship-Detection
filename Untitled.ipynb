{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4\n",
    "EDGE_CROP = 16\n",
    "NB_EPOCHS = 5\n",
    "GAUSSIAN_NOISE = 0.1\n",
    "UPSAMPLE_MODE = 'SIMPLE'\n",
    "# downsampling inside the network\n",
    "NET_SCALING = None\n",
    "# downsampling in preprocessing\n",
    "IMG_SCALING = (1, 1)\n",
    "# number of validation images to use\n",
    "VALID_IMG_COUNT = 400\n",
    "# maximum number of steps_per_epoch in training\n",
    "MAX_TRAIN_STEPS = 200\n",
    "AUGMENT_BRIGHTNESS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 驱动器 D 中的卷没有标签。\n",
      " 卷的序列号是 E693-9C52\n",
      "\n",
      " D:\\EC601\\dataset 的目录\n",
      "\n",
      "2018/12/07  00:42    <DIR>          .\n",
      "2018/12/07  00:42    <DIR>          ..\n",
      "2018/09/26  12:29    <DIR>          test\n",
      "2018/09/17  12:51    13,063,727,185 test.zip\n",
      "2018/09/17  12:39         6,157,863 test_ship_segmentations.csv.zip\n",
      "2018/12/07  01:27    <DIR>          train\n",
      "2018/09/17  13:06    15,319,664,584 train.zip\n",
      "2018/07/30  03:20        30,403,877 train_ship_segmentations.csv\n",
      "2018/09/17  12:39        12,648,942 train_ship_segmentations.csv.zip\n",
      "               5 个文件 28,432,602,451 字节\n",
      "               4 个目录 61,662,429,184 可用字节\n"
     ]
    }
   ],
   "source": [
    "ls D:\\EC601\\dataset\\\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from skimage.io import imread\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from skimage.util.montage import montage2d as montage\n",
    "montage_rgb = lambda x: np.stack([montage(x[:, :, :, i]) for i in range(x.shape[3])], -1)\n",
    "ship_dir = 'D:\\EC601\\dataset'\n",
    "train_image_dir = os.path.join(ship_dir, 'train')\n",
    "test_image_dir = os.path.join(ship_dir, 'test')\n",
    "import gc; gc.enable() # memory is tight\n",
    "\n",
    "from skimage.morphology import label\n",
    "def multi_rle_encode(img):\n",
    "    labels = label(img[:, :, 0])\n",
    "    return [rle_encode(labels==k) for k in np.unique(labels[labels>0])]\n",
    "\n",
    "# ref: https://www.kaggle.com/paulorzp/run-length-encode-and-decode\n",
    "def rle_encode(img):\n",
    "    '''\n",
    "    img: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formated\n",
    "    '''\n",
    "    pixels = img.T.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "def rle_decode(mask_rle, shape=(768, 768)):\n",
    "    '''\n",
    "    mask_rle: run-length as string formated (start length)\n",
    "    shape: (height,width) of array to return \n",
    "    Returns numpy array, 1 - mask, 0 - background\n",
    "    '''\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return img.reshape(shape).T  # Needed to align to RLE direction\n",
    "\n",
    "def masks_as_image(in_mask_list):\n",
    "    # Take the individual ship masks and create a single mask array for all ships\n",
    "    all_masks = np.zeros((768, 768), dtype = np.int16)\n",
    "    #if isinstance(in_mask_list, list):\n",
    "    for mask in in_mask_list:\n",
    "        if isinstance(mask, str):\n",
    "            all_masks += rle_decode(mask)\n",
    "    return np.expand_dims(all_masks, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131030 masks found\n",
      "104070\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>EncodedPixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00003e153.jpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000155de5.jpg</td>\n",
       "      <td>264661 17 265429 33 266197 33 266965 33 267733...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00021ddc3.jpg</td>\n",
       "      <td>101361 1 102128 3 102896 4 103663 6 104430 9 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00021ddc3.jpg</td>\n",
       "      <td>95225 2 95992 5 96760 7 97527 9 98294 9 99062 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00021ddc3.jpg</td>\n",
       "      <td>74444 4 75212 4 75980 4 76748 4 77517 3 78285 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ImageId                                      EncodedPixels\n",
       "0  00003e153.jpg                                                NaN\n",
       "1  000155de5.jpg  264661 17 265429 33 266197 33 266965 33 267733...\n",
       "2  00021ddc3.jpg  101361 1 102128 3 102896 4 103663 6 104430 9 1...\n",
       "3  00021ddc3.jpg  95225 2 95992 5 96760 7 97527 9 98294 9 99062 ...\n",
       "4  00021ddc3.jpg  74444 4 75212 4 75980 4 76748 4 77517 3 78285 ..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masks = pd.read_csv(os.path.join('D:\\EC601\\dataset',\n",
    "                                 'train_ship_segmentations.csv'))\n",
    "print(masks.shape[0], 'masks found')\n",
    "print(masks['ImageId'].value_counts().shape[0])\n",
    "masks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>ships</th>\n",
       "      <th>has_ship</th>\n",
       "      <th>has_ship_vec</th>\n",
       "      <th>file_size_kb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>56080</th>\n",
       "      <td>89cd711b2.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[1.0]</td>\n",
       "      <td>231.366211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23266</th>\n",
       "      <td>392745801.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>113.910156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82263</th>\n",
       "      <td>ca669c2c8.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>201.424805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61211</th>\n",
       "      <td>967cb8fe8.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>174.464844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89072</th>\n",
       "      <td>db5f6bdbd.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>256.169922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ImageId  ships  has_ship has_ship_vec  file_size_kb\n",
       "56080  89cd711b2.jpg      1       1.0        [1.0]    231.366211\n",
       "23266  392745801.jpg      0       0.0        [0.0]    113.910156\n",
       "82263  ca669c2c8.jpg      0       0.0        [0.0]    201.424805\n",
       "61211  967cb8fe8.jpg      0       0.0        [0.0]    174.464844\n",
       "89072  db5f6bdbd.jpg      0       0.0        [0.0]    256.169922"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "masks['ships'] = masks['EncodedPixels'].map(lambda c_row: 1 if isinstance(c_row, str) else 0)\n",
    "unique_img_ids = masks.groupby('ImageId').agg({'ships': 'sum'}).reset_index()\n",
    "unique_img_ids['has_ship'] = unique_img_ids['ships'].map(lambda x: 1.0 if x>0 else 0.0)\n",
    "unique_img_ids['has_ship_vec'] = unique_img_ids['has_ship'].map(lambda x: [x])\n",
    "# some files are too small/corrupt\n",
    "unique_img_ids['file_size_kb'] = unique_img_ids['ImageId'].map(lambda c_img_id: \n",
    "                                                               os.stat(os.path.join(train_image_dir, \n",
    "                                                                                    c_img_id)).st_size/1024)\n",
    "unique_img_ids = unique_img_ids[unique_img_ids['file_size_kb']>50] # keep only 50kb files\n",
    "unique_img_ids['file_size_kb'].hist()\n",
    "masks.drop(['ships'], axis=1, inplace=True)\n",
    "unique_img_ids.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91008 training masks\n",
      "39006 validation masks\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_ids, valid_ids = train_test_split(unique_img_ids, \n",
    "                 test_size = 0.3, \n",
    "                 stratify = unique_img_ids['ships'])\n",
    "train_df = pd.merge(masks, train_ids)\n",
    "valid_df = pd.merge(masks, valid_ids)\n",
    "print(train_df.shape[0], 'training masks')\n",
    "print(valid_df.shape[0], 'validation masks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x18a20c55b38>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df['grouped_ship_count'] = train_df['ships'].map(lambda x: (x+1)//2).clip(0, 7)\n",
    "def sample_ships(in_df, base_rep_val=1500):\n",
    "    if in_df['ships'].values[0]==0:\n",
    "        return in_df.sample(base_rep_val//3) # even more strongly undersample no ships\n",
    "    else:\n",
    "        return in_df.sample(base_rep_val, replace=(in_df.shape[0]<base_rep_val))\n",
    "    \n",
    "balanced_train_df = train_df.groupby('grouped_ship_count').apply(sample_ships)\n",
    "balanced_train_df['ships'].hist(bins=np.arange(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11000, 7)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_image_gen(in_df, batch_size = BATCH_SIZE):\n",
    "    all_batches = list(in_df.groupby('ImageId'))\n",
    "    out_rgb = []\n",
    "    out_mask = []\n",
    "    while True:\n",
    "        np.random.shuffle(all_batches)\n",
    "        for c_img_id, c_masks in all_batches:\n",
    "            rgb_path = os.path.join(train_image_dir, c_img_id)\n",
    "            c_img = imread(rgb_path)\n",
    "            c_mask = masks_as_image(c_masks['EncodedPixels'].values)\n",
    "            if IMG_SCALING is not None:\n",
    "                c_img = c_img[::IMG_SCALING[0], ::IMG_SCALING[1]]\n",
    "                c_mask = c_mask[::IMG_SCALING[0], ::IMG_SCALING[1]]\n",
    "            out_rgb += [c_img]\n",
    "            out_mask += [c_mask]\n",
    "            if len(out_rgb)>=batch_size:\n",
    "                yield np.stack(out_rgb, 0)/255.0, np.stack(out_mask, 0)\n",
    "                out_rgb, out_mask=[], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 768, 768, 3) (400, 768, 768, 1)\n"
     ]
    }
   ],
   "source": [
    "valid_x, valid_y = next(make_image_gen(valid_df, VALID_IMG_COUNT))\n",
    "print(valid_x.shape, valid_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "dg_args = dict(featurewise_center = False, \n",
    "                  samplewise_center = False,\n",
    "                  rotation_range = 15, \n",
    "                  width_shift_range = 0.1, \n",
    "                  height_shift_range = 0.1, \n",
    "                  shear_range = 0.01,\n",
    "                  zoom_range = [0.9, 1.25],  \n",
    "                  horizontal_flip = True, \n",
    "                  vertical_flip = True,\n",
    "                  fill_mode = 'reflect',\n",
    "                   data_format = 'channels_last')\n",
    "# brightness can be problematic since it seems to change the labels differently from the images \n",
    "if AUGMENT_BRIGHTNESS:\n",
    "    dg_args[' brightness_range'] = [0.5, 1.5]\n",
    "image_gen = ImageDataGenerator(**dg_args)\n",
    "\n",
    "if AUGMENT_BRIGHTNESS:\n",
    "    dg_args.pop('brightness_range')\n",
    "label_gen = ImageDataGenerator(**dg_args)\n",
    "\n",
    "def create_aug_gen(in_gen, seed = None):\n",
    "    np.random.seed(seed if seed is not None else np.random.choice(range(9999)))\n",
    "    for in_x, in_y in in_gen:\n",
    "        seed = np.random.choice(range(9999))\n",
    "        # keep the seeds syncronized otherwise the augmentation to the images is different from the masks\n",
    "        g_x = image_gen.flow(255*in_x, \n",
    "                             batch_size = in_x.shape[0], \n",
    "                             seed = seed, \n",
    "                             shuffle=True)\n",
    "        g_y = label_gen.flow(in_y, \n",
    "                             batch_size = in_x.shape[0], \n",
    "                             seed = seed, \n",
    "                             shuffle=True)\n",
    "\n",
    "        yield next(g_x)/255.0, next(g_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "262"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import six\n",
    "\n",
    "from random import randint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-white')\n",
    "import seaborn as sns\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from skimage.transform import resize\n",
    "\n",
    "\n",
    "from keras import Model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.models import load_model\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Input, Conv2D, Conv2DTranspose, MaxPooling2D, concatenate, Dropout,BatchNormalization\n",
    "from keras.layers import Conv2D, Concatenate, MaxPooling2D\n",
    "from keras.layers import UpSampling2D, Dropout, BatchNormalization\n",
    "from tqdm import tqdm_notebook\n",
    "from keras import initializers\n",
    "from keras import regularizers\n",
    "from keras import constraints\n",
    "from keras.utils import conv_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.engine.topology import get_source_inputs\n",
    "from keras.engine import InputSpec\n",
    "from keras import backend as K\n",
    "from keras.regularizers import l2\n",
    "\n",
    "from keras.engine.topology import Input\n",
    "from keras.engine.training import Model\n",
    "from keras.layers.convolutional import Conv2D, UpSampling2D, Conv2DTranspose\n",
    "from keras.layers.core import Activation, SpatialDropout2D\n",
    "from keras.layers.merge import concatenate,add\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.pooling import MaxPooling2D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Upsample layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2DTranspose\n",
    "from keras.layers import UpSampling2D\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Concatenate\n",
    "\n",
    "def handle_block_names_decode(stage):\n",
    "    conv_name = 'decoder_stage{}_conv'.format(stage)\n",
    "    bn_name = 'decoder_stage{}_bn'.format(stage)\n",
    "    relu_name = 'decoder_stage{}_relu'.format(stage)\n",
    "    up_name = 'decoder_stage{}_upsample'.format(stage)\n",
    "    return conv_name, bn_name, relu_name, up_name\n",
    "\n",
    "\n",
    "def Upsample2D_block(filters, stage, kernel_size=(3,3), upsample_rate=(2,2),\n",
    "                     batchnorm=False, skip=None):\n",
    "\n",
    "    def layer(input_tensor):\n",
    "\n",
    "        conv_name, bn_name, relu_name, up_name = handle_block_names_decode(stage)\n",
    "\n",
    "        x = UpSampling2D(size=upsample_rate, name=up_name)(input_tensor)\n",
    "\n",
    "        if skip is not None:\n",
    "            x = Concatenate()([x, skip])\n",
    "\n",
    "        x = Conv2D(filters, kernel_size, padding='same', name=conv_name+'1')(x)\n",
    "        if batchnorm:\n",
    "            x = BatchNormalization(name=bn_name+'1')(x)\n",
    "        x = Activation('relu', name=relu_name+'1')(x)\n",
    "\n",
    "        x = Conv2D(filters, kernel_size, padding='same', name=conv_name+'2')(x)\n",
    "        if batchnorm:\n",
    "            x = BatchNormalization(name=bn_name+'2')(x)\n",
    "        x = Activation('relu', name=relu_name+'2')(x)\n",
    "\n",
    "        return x\n",
    "    return layer\n",
    "\n",
    "\n",
    "def Transpose2D_block(filters, stage, kernel_size=(3,3), upsample_rate=(2,2),\n",
    "                      transpose_kernel_size=(4,4), batchnorm=False, skip=None):\n",
    "\n",
    "    def layer(input_tensor):\n",
    "\n",
    "        conv_name, bn_name, relu_name, up_name = handle_block_names_decode(stage)\n",
    "\n",
    "        x = Conv2DTranspose(filters, transpose_kernel_size, strides=upsample_rate,\n",
    "                            padding='same', name=up_name)(input_tensor)\n",
    "        if batchnorm:\n",
    "            x = BatchNormalization(name=bn_name+'1')(x)\n",
    "        x = Activation('relu', name=relu_name+'1')(x)\n",
    "\n",
    "        if skip is not None:\n",
    "            x = Concatenate()([x, skip])\n",
    "\n",
    "        x = Conv2D(filters, kernel_size, padding='same', name=conv_name+'2')(x)\n",
    "        if batchnorm:\n",
    "            x = BatchNormalization(name=bn_name+'2')(x)\n",
    "        x = Activation('relu', name=relu_name+'2')(x)\n",
    "\n",
    "        return x\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Unet model (Decoder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_unet(backbone, classes, last_block_filters, skip_layers,\n",
    "               n_upsample_blocks=5, upsample_rates=(2,2,2,2,2),\n",
    "               block_type='upsampling', activation='sigmoid',\n",
    "               **kwargs):\n",
    "\n",
    "    input = backbone.input\n",
    "    x = backbone.output\n",
    "    print(x)\n",
    "    if block_type == 'transpose':\n",
    "        up_block = Transpose2D_block\n",
    "    else:\n",
    "        up_block = Upsample2D_block\n",
    "\n",
    "    # convert layer names to indices\n",
    "    skip_layers = ([get_layer_number(backbone, l) if isinstance(l, str) else l\n",
    "                    for l in skip_layers])\n",
    "    for i in range(n_upsample_blocks):\n",
    "\n",
    "        # check if there is a skip connection\n",
    "        if i < len(skip_layers):\n",
    "            print(backbone.layers[skip_layers[i]])\n",
    "            print(backbone.layers[skip_layers[i]].output)\n",
    "            skip = backbone.layers[skip_layers[i]].output\n",
    "        else:\n",
    "            skip = None\n",
    "\n",
    "        up_size = (upsample_rates[i], upsample_rates[i])\n",
    "        filters = last_block_filters * 2**(n_upsample_blocks-(i+1))\n",
    "\n",
    "        x = up_block(filters, i, upsample_rate=up_size, skip=skip, **kwargs)(x)\n",
    "\n",
    "    if classes < 2:\n",
    "        activation = 'sigmoid'\n",
    "\n",
    "    x = Conv2D(classes, (3,3), padding='same', name='final_conv')(x)\n",
    "    x = Activation(activation, name=activation)(x)\n",
    "\n",
    "    model = Model(input, x)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Built ResNet34 model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Add\n",
    "from keras.layers import ZeroPadding2D\n",
    "\n",
    "def handle_block_names(stage, block):\n",
    "    name_base = 'stage{}_unit{}_'.format(stage + 1, block + 1)\n",
    "    conv_name = name_base + 'conv'\n",
    "    bn_name = name_base + 'bn'\n",
    "    relu_name = name_base + 'relu'\n",
    "    sc_name = name_base + 'sc'\n",
    "    return conv_name, bn_name, relu_name, sc_name\n",
    "\n",
    "\n",
    "def basic_identity_block(filters, stage, block):\n",
    "\n",
    "    def layer(input_tensor):\n",
    "        conv_params = get_conv_params()\n",
    "        bn_params = get_bn_params()\n",
    "        conv_name, bn_name, relu_name, sc_name = handle_block_names(stage, block)\n",
    "\n",
    "        x = BatchNormalization(name=bn_name + '1', **bn_params)(input_tensor)\n",
    "        x = Activation('relu', name=relu_name + '1')(x)\n",
    "        x = ZeroPadding2D(padding=(1, 1))(x)\n",
    "        x = Conv2D(filters, (3, 3), name=conv_name + '1', **conv_params)(x)\n",
    "\n",
    "        x = BatchNormalization(name=bn_name + '2', **bn_params)(x)\n",
    "        x = Activation('relu', name=relu_name + '2')(x)\n",
    "        x = ZeroPadding2D(padding=(1, 1))(x)\n",
    "        x = Conv2D(filters, (3, 3), name=conv_name + '2', **conv_params)(x)\n",
    "\n",
    "        x = Add()([x, input_tensor])\n",
    "        return x\n",
    "\n",
    "    return layer\n",
    "\n",
    "\n",
    "def basic_conv_block(filters, stage, block, strides=(2, 2)):\n",
    "\n",
    "    def layer(input_tensor):\n",
    "        conv_params = get_conv_params()\n",
    "        bn_params = get_bn_params()\n",
    "        conv_name, bn_name, relu_name, sc_name = handle_block_names(stage, block)\n",
    "\n",
    "        x = BatchNormalization(name=bn_name + '1', **bn_params)(input_tensor)\n",
    "        x = Activation('relu', name=relu_name + '1')(x)\n",
    "        shortcut = x\n",
    "        x = ZeroPadding2D(padding=(1, 1))(x)\n",
    "        x = Conv2D(filters, (3, 3), strides=strides, name=conv_name + '1', **conv_params)(x)\n",
    "\n",
    "        x = BatchNormalization(name=bn_name + '2', **bn_params)(x)\n",
    "        x = Activation('relu', name=relu_name + '2')(x)\n",
    "        x = ZeroPadding2D(padding=(1, 1))(x)\n",
    "        x = Conv2D(filters, (3, 3), name=conv_name + '2', **conv_params)(x)\n",
    "\n",
    "        shortcut = Conv2D(filters, (1, 1), name=sc_name, strides=strides, **conv_params)(shortcut)\n",
    "        x = Add()([x, shortcut])\n",
    "        return x\n",
    "\n",
    "    return layer\n",
    "\n",
    "\n",
    "def conv_block(filters, stage, block, strides=(2, 2)):\n",
    "    def layer(input_tensor):\n",
    "        conv_params = get_conv_params()\n",
    "        bn_params = get_bn_params()\n",
    "        conv_name, bn_name, relu_name, sc_name = handle_block_names(stage, block)\n",
    "\n",
    "        x = BatchNormalization(name=bn_name + '1', **bn_params)(input_tensor)\n",
    "        x = Activation('relu', name=relu_name + '1')(x)\n",
    "        shortcut = x\n",
    "        x = Conv2D(filters, (1, 1), name=conv_name + '1', **conv_params)(x)\n",
    "\n",
    "        x = BatchNormalization(name=bn_name + '2', **bn_params)(x)\n",
    "        x = Activation('relu', name=relu_name + '2')(x)\n",
    "        x = ZeroPadding2D(padding=(1, 1))(x)\n",
    "        x = Conv2D(filters, (3, 3), strides=strides, name=conv_name + '2', **conv_params)(x)\n",
    "\n",
    "        x = BatchNormalization(name=bn_name + '3', **bn_params)(x)\n",
    "        x = Activation('relu', name=relu_name + '3')(x)\n",
    "        x = Conv2D(filters*4, (1, 1), name=conv_name + '3', **conv_params)(x)\n",
    "\n",
    "        shortcut = Conv2D(filters*4, (1, 1), name=sc_name, strides=strides, **conv_params)(shortcut)\n",
    "        x = Add()([x, shortcut])\n",
    "        return x\n",
    "\n",
    "    return layer\n",
    "\n",
    "\n",
    "def identity_block(filters, stage, block):\n",
    "\n",
    "    def layer(input_tensor):\n",
    "        conv_params = get_conv_params()\n",
    "        bn_params = get_bn_params()\n",
    "        conv_name, bn_name, relu_name, sc_name = handle_block_names(stage, block)\n",
    "\n",
    "        x = BatchNormalization(name=bn_name + '1', **bn_params)(input_tensor)\n",
    "        x = Activation('relu', name=relu_name + '1')(x)\n",
    "        x = Conv2D(filters, (1, 1), name=conv_name + '1', **conv_params)(x)\n",
    "\n",
    "        x = BatchNormalization(name=bn_name + '2', **bn_params)(x)\n",
    "        x = Activation('relu', name=relu_name + '2')(x)\n",
    "        x = ZeroPadding2D(padding=(1, 1))(x)\n",
    "        x = Conv2D(filters, (3, 3), name=conv_name + '2', **conv_params)(x)\n",
    "\n",
    "        x = BatchNormalization(name=bn_name + '3', **bn_params)(x)\n",
    "        x = Activation('relu', name=relu_name + '3')(x)\n",
    "        x = Conv2D(filters*4, (1, 1), name=conv_name + '3', **conv_params)(x)\n",
    "\n",
    "        x = Add()([x, input_tensor])\n",
    "        return x\n",
    "\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conv_params(**params):\n",
    "    default_conv_params = {\n",
    "        'kernel_initializer': 'glorot_uniform',\n",
    "        'use_bias': False,\n",
    "        'padding': 'valid',\n",
    "    }\n",
    "    default_conv_params.update(params)\n",
    "    return default_conv_params\n",
    "\n",
    "\n",
    "def get_bn_params(**params):\n",
    "    default_bn_params = {\n",
    "        'axis': 3,\n",
    "        'momentum': 0.99,\n",
    "        'epsilon': 2e-5,\n",
    "        'center': True,\n",
    "        'scale': True,\n",
    "    }\n",
    "    default_bn_params.update(params)\n",
    "    return default_bn_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "from keras.layers import Input\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Activation\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.layers import ZeroPadding2D\n",
    "from keras.layers import Dense\n",
    "from keras.models import Model\n",
    "from keras.engine import get_source_inputs\n",
    "\n",
    "import keras\n",
    "from distutils.version import StrictVersion\n",
    "\n",
    "if StrictVersion(keras.__version__) < StrictVersion('2.2.0'):\n",
    "    from keras.applications.imagenet_utils import _obtain_input_shape\n",
    "else:\n",
    "    from keras_applications.imagenet_utils import _obtain_input_shape\n",
    "    \n",
    "def build_resnet(\n",
    "     repetitions=(2, 2, 2, 2),\n",
    "     include_top=True,\n",
    "     input_tensor=None,\n",
    "     input_shape=None,\n",
    "     classes=1000,\n",
    "     block_type='usual'):\n",
    "\n",
    "    # Determine proper input shape\n",
    "    input_shape = _obtain_input_shape(input_shape,\n",
    "                                      default_size=224,\n",
    "                                      min_size=197,\n",
    "                                      data_format='channels_last',\n",
    "                                      require_flatten=include_top)\n",
    "\n",
    "    if input_tensor is None:\n",
    "        img_input = Input(shape=input_shape, name='data')\n",
    "    else:\n",
    "        if not K.is_keras_tensor(input_tensor):\n",
    "            img_input = Input(tensor=input_tensor, shape=input_shape)\n",
    "        else:\n",
    "            img_input = input_tensor\n",
    "    \n",
    "    # get parameters for model layers\n",
    "    no_scale_bn_params = get_bn_params(scale=False)\n",
    "    bn_params = get_bn_params()\n",
    "    conv_params = get_conv_params()\n",
    "    init_filters = 64\n",
    "\n",
    "    if block_type == 'basic':\n",
    "        conv_block = basic_conv_block\n",
    "        identity_block = basic_identity_block\n",
    "    else:\n",
    "        conv_block = usual_conv_block\n",
    "        identity_block = usual_identity_block\n",
    "    \n",
    "    # resnet bottom\n",
    "    x = BatchNormalization(name='bn_data', **no_scale_bn_params)(img_input)\n",
    "    x = ZeroPadding2D(padding=(3, 3))(x)\n",
    "    x = Conv2D(init_filters, (7, 7), strides=(2, 2), name='conv0', **conv_params)(x)\n",
    "    x = BatchNormalization(name='bn0', **bn_params)(x)\n",
    "    x = Activation('relu', name='relu0')(x)\n",
    "    x = ZeroPadding2D(padding=(1, 1))(x)\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='valid', name='pooling0')(x)\n",
    "    \n",
    "    # resnet body\n",
    "    for stage, rep in enumerate(repetitions):\n",
    "        for block in range(rep):\n",
    "            \n",
    "            filters = init_filters * (2**stage)\n",
    "            \n",
    "            # first block of first stage without strides because we have maxpooling before\n",
    "            if block == 0 and stage == 0:\n",
    "                x = conv_block(filters, stage, block, strides=(1, 1))(x)\n",
    "                \n",
    "            elif block == 0:\n",
    "                x = conv_block(filters, stage, block, strides=(2, 2))(x)\n",
    "                \n",
    "            else:\n",
    "                x = identity_block(filters, stage, block)(x)\n",
    "                \n",
    "    x = BatchNormalization(name='bn1', **bn_params)(x)\n",
    "    x = Activation('relu', name='relu1')(x)\n",
    "\n",
    "    # resnet top\n",
    "    if include_top:\n",
    "        x = GlobalAveragePooling2D(name='pool1')(x)\n",
    "        x = Dense(classes, name='fc1')(x)\n",
    "        x = Activation('softmax', name='softmax')(x)\n",
    "\n",
    "    # Ensure that the model takes into account any potential predecessors of `input_tensor`.\n",
    "    if input_tensor is not None:\n",
    "        inputs = get_source_inputs(input_tensor)\n",
    "    else:\n",
    "        inputs = img_input\n",
    "        \n",
    "    # Create model.\n",
    "    model = Model(inputs, x)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import get_file\n",
    "\n",
    "\n",
    "def find_weights(weights_collection, model_name, dataset, include_top):\n",
    "    w = list(filter(lambda x: x['model'] == model_name, weights_collection))\n",
    "    w = list(filter(lambda x: x['dataset'] == dataset, w))\n",
    "    w = list(filter(lambda x: x['include_top'] == include_top, w))\n",
    "    return w\n",
    "\n",
    "\n",
    "def load_model_weights(weights_collection, model, dataset, classes, include_top):\n",
    "    weights = find_weights(weights_collection, model.name, dataset, include_top)\n",
    "\n",
    "    if weights:\n",
    "        weights = weights[0]\n",
    "\n",
    "        if include_top and weights['classes'] != classes:\n",
    "            raise ValueError('If using `weights` and `include_top`'\n",
    "                             ' as true, `classes` should be {}'.format(weights['classes']))\n",
    "\n",
    "        weights_path = get_file(weights['name'],\n",
    "                                weights['url'],\n",
    "                                cache_subdir='models',\n",
    "                                md5_hash=weights['md5'])\n",
    "\n",
    "        model.load_weights(weights_path)\n",
    "\n",
    "    else:\n",
    "        raise ValueError('There is no weights for such configuration: ' +\n",
    "                         'model = {}, dataset = {}, '.format(model.name, dataset) +\n",
    "                         'classes = {}, include_top = {}.'.format(classes, include_top))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_collection = [\n",
    "\n",
    "    # ResNet34\n",
    "    {\n",
    "        'model': 'resnet34',\n",
    "        'dataset': 'imagenet',\n",
    "        'classes': 1000,\n",
    "        'include_top': True,\n",
    "        'url': 'https://github.com/qubvel/classification_models/releases/download/0.0.1/resnet34_imagenet_1000.h5',\n",
    "        'name': 'resnet34_imagenet_1000.h5',\n",
    "        'md5': '2ac8277412f65e5d047f255bcbd10383',\n",
    "    },\n",
    "\n",
    "    {\n",
    "        'model': 'resnet34',\n",
    "        'dataset': 'imagenet',\n",
    "        'classes': 1000,\n",
    "        'include_top': False,\n",
    "        'url': 'https://github.com/qubvel/classification_models/releases/download/0.0.1/resnet34_imagenet_1000_no_top.h5',\n",
    "        'name': 'resnet34_imagenet_1000_no_top.h5',\n",
    "        'md5': '8caaa0ad39d927cb8ba5385bf945d582',\n",
    "    }]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Buil Unet model base on ResNet34\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Freeze Encoder weight if needed\n",
    "\n",
    "def freeze_model(model):\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = False\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UResNet34(input_shape=(None, None, 3), classes=1, decoder_filters=16, decoder_block_type='upsampling',\n",
    "                       encoder_weights=None, input_tensor=None, activation='sigmoid', **kwargs):\n",
    "\n",
    "    backbone = build_resnet(input_tensor=None,\n",
    "                         input_shape=input_shape,\n",
    "                         repetitions=(3, 4, 6, 3),\n",
    "                         classes=classes,\n",
    "                         include_top=False,\n",
    "                         block_type='basic')\n",
    "    backbone.name = 'resnet34'\n",
    "    \n",
    "    if encoder_weights == True:\n",
    "        load_model_weights(weights_collection, backbone , dataset= 'imagenet', classes = 1, include_top=False)\n",
    "    \n",
    "    skip_connections = list([129, 74, 37, 5]) # for resnet 34\n",
    "    model = build_unet(backbone, classes, decoder_filters,\n",
    "                       skip_connections, block_type=decoder_block_type,\n",
    "                       activation=activation, **kwargs)\n",
    "    model.name = 'u-resnet34'\n",
    "    \n",
    "    #freeze_model(backbone)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"relu1_1/Relu:0\", shape=(?, 24, 24, 512), dtype=float32)\n",
      "<keras.layers.core.Activation object at 0x0000018A29227DA0>\n",
      "Tensor(\"stage4_unit1_relu1_1/Relu:0\", shape=(?, 48, 48, 256), dtype=float32)\n",
      "<keras.layers.core.Activation object at 0x0000018A137E6AC8>\n",
      "Tensor(\"stage3_unit1_relu1_1/Relu:0\", shape=(?, 96, 96, 128), dtype=float32)\n",
      "<keras.layers.core.Activation object at 0x0000018A11FF8630>\n",
      "Tensor(\"stage2_unit1_relu1_1/Relu:0\", shape=(?, 192, 192, 64), dtype=float32)\n",
      "<keras.layers.core.Activation object at 0x0000018A06E780F0>\n",
      "Tensor(\"relu0_1/Relu:0\", shape=(?, 384, 384, 64), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "seg_model = UResNet34(input_shape=(768,768,3),encoder_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "data (InputLayer)               (None, 768, 768, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bn_data (BatchNormalization)    (None, 768, 768, 3)  9           data[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_35 (ZeroPadding2 (None, 774, 774, 3)  0           bn_data[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv0 (Conv2D)                  (None, 384, 384, 64) 9408        zero_padding2d_35[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "bn0 (BatchNormalization)        (None, 384, 384, 64) 256         conv0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "relu0 (Activation)              (None, 384, 384, 64) 0           bn0[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_36 (ZeroPadding2 (None, 386, 386, 64) 0           relu0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pooling0 (MaxPooling2D)         (None, 192, 192, 64) 0           zero_padding2d_36[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_bn1 (BatchNormaliz (None, 192, 192, 64) 256         pooling0[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_relu1 (Activation) (None, 192, 192, 64) 0           stage1_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_37 (ZeroPadding2 (None, 194, 194, 64) 0           stage1_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_conv1 (Conv2D)     (None, 192, 192, 64) 36864       zero_padding2d_37[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_bn2 (BatchNormaliz (None, 192, 192, 64) 256         stage1_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_relu2 (Activation) (None, 192, 192, 64) 0           stage1_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_38 (ZeroPadding2 (None, 194, 194, 64) 0           stage1_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_conv2 (Conv2D)     (None, 192, 192, 64) 36864       zero_padding2d_38[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_sc (Conv2D)        (None, 192, 192, 64) 4096        stage1_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 192, 192, 64) 0           stage1_unit1_conv2[0][0]         \n",
      "                                                                 stage1_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_bn1 (BatchNormaliz (None, 192, 192, 64) 256         add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_relu1 (Activation) (None, 192, 192, 64) 0           stage1_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_39 (ZeroPadding2 (None, 194, 194, 64) 0           stage1_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_conv1 (Conv2D)     (None, 192, 192, 64) 36864       zero_padding2d_39[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_bn2 (BatchNormaliz (None, 192, 192, 64) 256         stage1_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_relu2 (Activation) (None, 192, 192, 64) 0           stage1_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_40 (ZeroPadding2 (None, 194, 194, 64) 0           stage1_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_conv2 (Conv2D)     (None, 192, 192, 64) 36864       zero_padding2d_40[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 192, 192, 64) 0           stage1_unit2_conv2[0][0]         \n",
      "                                                                 add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_bn1 (BatchNormaliz (None, 192, 192, 64) 256         add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_relu1 (Activation) (None, 192, 192, 64) 0           stage1_unit3_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_41 (ZeroPadding2 (None, 194, 194, 64) 0           stage1_unit3_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_conv1 (Conv2D)     (None, 192, 192, 64) 36864       zero_padding2d_41[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_bn2 (BatchNormaliz (None, 192, 192, 64) 256         stage1_unit3_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_relu2 (Activation) (None, 192, 192, 64) 0           stage1_unit3_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_42 (ZeroPadding2 (None, 194, 194, 64) 0           stage1_unit3_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_conv2 (Conv2D)     (None, 192, 192, 64) 36864       zero_padding2d_42[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 192, 192, 64) 0           stage1_unit3_conv2[0][0]         \n",
      "                                                                 add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_bn1 (BatchNormaliz (None, 192, 192, 64) 256         add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_relu1 (Activation) (None, 192, 192, 64) 0           stage2_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_43 (ZeroPadding2 (None, 194, 194, 64) 0           stage2_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_conv1 (Conv2D)     (None, 96, 96, 128)  73728       zero_padding2d_43[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_bn2 (BatchNormaliz (None, 96, 96, 128)  512         stage2_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_relu2 (Activation) (None, 96, 96, 128)  0           stage2_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_44 (ZeroPadding2 (None, 98, 98, 128)  0           stage2_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_conv2 (Conv2D)     (None, 96, 96, 128)  147456      zero_padding2d_44[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_sc (Conv2D)        (None, 96, 96, 128)  8192        stage2_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, 96, 96, 128)  0           stage2_unit1_conv2[0][0]         \n",
      "                                                                 stage2_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_bn1 (BatchNormaliz (None, 96, 96, 128)  512         add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_relu1 (Activation) (None, 96, 96, 128)  0           stage2_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_45 (ZeroPadding2 (None, 98, 98, 128)  0           stage2_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_conv1 (Conv2D)     (None, 96, 96, 128)  147456      zero_padding2d_45[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_bn2 (BatchNormaliz (None, 96, 96, 128)  512         stage2_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_relu2 (Activation) (None, 96, 96, 128)  0           stage2_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_46 (ZeroPadding2 (None, 98, 98, 128)  0           stage2_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_conv2 (Conv2D)     (None, 96, 96, 128)  147456      zero_padding2d_46[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, 96, 96, 128)  0           stage2_unit2_conv2[0][0]         \n",
      "                                                                 add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_bn1 (BatchNormaliz (None, 96, 96, 128)  512         add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_relu1 (Activation) (None, 96, 96, 128)  0           stage2_unit3_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_47 (ZeroPadding2 (None, 98, 98, 128)  0           stage2_unit3_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_conv1 (Conv2D)     (None, 96, 96, 128)  147456      zero_padding2d_47[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_bn2 (BatchNormaliz (None, 96, 96, 128)  512         stage2_unit3_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_relu2 (Activation) (None, 96, 96, 128)  0           stage2_unit3_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_48 (ZeroPadding2 (None, 98, 98, 128)  0           stage2_unit3_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_conv2 (Conv2D)     (None, 96, 96, 128)  147456      zero_padding2d_48[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, 96, 96, 128)  0           stage2_unit3_conv2[0][0]         \n",
      "                                                                 add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_bn1 (BatchNormaliz (None, 96, 96, 128)  512         add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_relu1 (Activation) (None, 96, 96, 128)  0           stage2_unit4_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_49 (ZeroPadding2 (None, 98, 98, 128)  0           stage2_unit4_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_conv1 (Conv2D)     (None, 96, 96, 128)  147456      zero_padding2d_49[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_bn2 (BatchNormaliz (None, 96, 96, 128)  512         stage2_unit4_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_relu2 (Activation) (None, 96, 96, 128)  0           stage2_unit4_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_50 (ZeroPadding2 (None, 98, 98, 128)  0           stage2_unit4_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_conv2 (Conv2D)     (None, 96, 96, 128)  147456      zero_padding2d_50[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_23 (Add)                    (None, 96, 96, 128)  0           stage2_unit4_conv2[0][0]         \n",
      "                                                                 add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_bn1 (BatchNormaliz (None, 96, 96, 128)  512         add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_relu1 (Activation) (None, 96, 96, 128)  0           stage3_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_51 (ZeroPadding2 (None, 98, 98, 128)  0           stage3_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_conv1 (Conv2D)     (None, 48, 48, 256)  294912      zero_padding2d_51[0][0]          \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stage3_unit1_bn2 (BatchNormaliz (None, 48, 48, 256)  1024        stage3_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_relu2 (Activation) (None, 48, 48, 256)  0           stage3_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_52 (ZeroPadding2 (None, 50, 50, 256)  0           stage3_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_conv2 (Conv2D)     (None, 48, 48, 256)  589824      zero_padding2d_52[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_sc (Conv2D)        (None, 48, 48, 256)  32768       stage3_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_24 (Add)                    (None, 48, 48, 256)  0           stage3_unit1_conv2[0][0]         \n",
      "                                                                 stage3_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_bn1 (BatchNormaliz (None, 48, 48, 256)  1024        add_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_relu1 (Activation) (None, 48, 48, 256)  0           stage3_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_53 (ZeroPadding2 (None, 50, 50, 256)  0           stage3_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_conv1 (Conv2D)     (None, 48, 48, 256)  589824      zero_padding2d_53[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_bn2 (BatchNormaliz (None, 48, 48, 256)  1024        stage3_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_relu2 (Activation) (None, 48, 48, 256)  0           stage3_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_54 (ZeroPadding2 (None, 50, 50, 256)  0           stage3_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_conv2 (Conv2D)     (None, 48, 48, 256)  589824      zero_padding2d_54[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_25 (Add)                    (None, 48, 48, 256)  0           stage3_unit2_conv2[0][0]         \n",
      "                                                                 add_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_bn1 (BatchNormaliz (None, 48, 48, 256)  1024        add_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_relu1 (Activation) (None, 48, 48, 256)  0           stage3_unit3_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_55 (ZeroPadding2 (None, 50, 50, 256)  0           stage3_unit3_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_conv1 (Conv2D)     (None, 48, 48, 256)  589824      zero_padding2d_55[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_bn2 (BatchNormaliz (None, 48, 48, 256)  1024        stage3_unit3_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_relu2 (Activation) (None, 48, 48, 256)  0           stage3_unit3_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_56 (ZeroPadding2 (None, 50, 50, 256)  0           stage3_unit3_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_conv2 (Conv2D)     (None, 48, 48, 256)  589824      zero_padding2d_56[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_26 (Add)                    (None, 48, 48, 256)  0           stage3_unit3_conv2[0][0]         \n",
      "                                                                 add_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_bn1 (BatchNormaliz (None, 48, 48, 256)  1024        add_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_relu1 (Activation) (None, 48, 48, 256)  0           stage3_unit4_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_57 (ZeroPadding2 (None, 50, 50, 256)  0           stage3_unit4_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_conv1 (Conv2D)     (None, 48, 48, 256)  589824      zero_padding2d_57[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_bn2 (BatchNormaliz (None, 48, 48, 256)  1024        stage3_unit4_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_relu2 (Activation) (None, 48, 48, 256)  0           stage3_unit4_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_58 (ZeroPadding2 (None, 50, 50, 256)  0           stage3_unit4_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_conv2 (Conv2D)     (None, 48, 48, 256)  589824      zero_padding2d_58[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_27 (Add)                    (None, 48, 48, 256)  0           stage3_unit4_conv2[0][0]         \n",
      "                                                                 add_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_bn1 (BatchNormaliz (None, 48, 48, 256)  1024        add_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_relu1 (Activation) (None, 48, 48, 256)  0           stage3_unit5_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_59 (ZeroPadding2 (None, 50, 50, 256)  0           stage3_unit5_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_conv1 (Conv2D)     (None, 48, 48, 256)  589824      zero_padding2d_59[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_bn2 (BatchNormaliz (None, 48, 48, 256)  1024        stage3_unit5_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_relu2 (Activation) (None, 48, 48, 256)  0           stage3_unit5_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_60 (ZeroPadding2 (None, 50, 50, 256)  0           stage3_unit5_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_conv2 (Conv2D)     (None, 48, 48, 256)  589824      zero_padding2d_60[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_28 (Add)                    (None, 48, 48, 256)  0           stage3_unit5_conv2[0][0]         \n",
      "                                                                 add_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_bn1 (BatchNormaliz (None, 48, 48, 256)  1024        add_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_relu1 (Activation) (None, 48, 48, 256)  0           stage3_unit6_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_61 (ZeroPadding2 (None, 50, 50, 256)  0           stage3_unit6_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_conv1 (Conv2D)     (None, 48, 48, 256)  589824      zero_padding2d_61[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_bn2 (BatchNormaliz (None, 48, 48, 256)  1024        stage3_unit6_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_relu2 (Activation) (None, 48, 48, 256)  0           stage3_unit6_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_62 (ZeroPadding2 (None, 50, 50, 256)  0           stage3_unit6_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_conv2 (Conv2D)     (None, 48, 48, 256)  589824      zero_padding2d_62[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_29 (Add)                    (None, 48, 48, 256)  0           stage3_unit6_conv2[0][0]         \n",
      "                                                                 add_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_bn1 (BatchNormaliz (None, 48, 48, 256)  1024        add_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_relu1 (Activation) (None, 48, 48, 256)  0           stage4_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_63 (ZeroPadding2 (None, 50, 50, 256)  0           stage4_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_conv1 (Conv2D)     (None, 24, 24, 512)  1179648     zero_padding2d_63[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_bn2 (BatchNormaliz (None, 24, 24, 512)  2048        stage4_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_relu2 (Activation) (None, 24, 24, 512)  0           stage4_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_64 (ZeroPadding2 (None, 26, 26, 512)  0           stage4_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_conv2 (Conv2D)     (None, 24, 24, 512)  2359296     zero_padding2d_64[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_sc (Conv2D)        (None, 24, 24, 512)  131072      stage4_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_30 (Add)                    (None, 24, 24, 512)  0           stage4_unit1_conv2[0][0]         \n",
      "                                                                 stage4_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_bn1 (BatchNormaliz (None, 24, 24, 512)  2048        add_30[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_relu1 (Activation) (None, 24, 24, 512)  0           stage4_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_65 (ZeroPadding2 (None, 26, 26, 512)  0           stage4_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_conv1 (Conv2D)     (None, 24, 24, 512)  2359296     zero_padding2d_65[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_bn2 (BatchNormaliz (None, 24, 24, 512)  2048        stage4_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_relu2 (Activation) (None, 24, 24, 512)  0           stage4_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_66 (ZeroPadding2 (None, 26, 26, 512)  0           stage4_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_conv2 (Conv2D)     (None, 24, 24, 512)  2359296     zero_padding2d_66[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_31 (Add)                    (None, 24, 24, 512)  0           stage4_unit2_conv2[0][0]         \n",
      "                                                                 add_30[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_bn1 (BatchNormaliz (None, 24, 24, 512)  2048        add_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_relu1 (Activation) (None, 24, 24, 512)  0           stage4_unit3_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_67 (ZeroPadding2 (None, 26, 26, 512)  0           stage4_unit3_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_conv1 (Conv2D)     (None, 24, 24, 512)  2359296     zero_padding2d_67[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_bn2 (BatchNormaliz (None, 24, 24, 512)  2048        stage4_unit3_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_relu2 (Activation) (None, 24, 24, 512)  0           stage4_unit3_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_68 (ZeroPadding2 (None, 26, 26, 512)  0           stage4_unit3_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_conv2 (Conv2D)     (None, 24, 24, 512)  2359296     zero_padding2d_68[0][0]          \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add_32 (Add)                    (None, 24, 24, 512)  0           stage4_unit3_conv2[0][0]         \n",
      "                                                                 add_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bn1 (BatchNormalization)        (None, 24, 24, 512)  2048        add_32[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu1 (Activation)              (None, 24, 24, 512)  0           bn1[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0_upsample (UpSamp (None, 48, 48, 512)  0           relu1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 48, 48, 768)  0           decoder_stage0_upsample[0][0]    \n",
      "                                                                 stage4_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0_conv1 (Conv2D)   (None, 48, 48, 256)  1769728     concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0_relu1 (Activatio (None, 48, 48, 256)  0           decoder_stage0_conv1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0_conv2 (Conv2D)   (None, 48, 48, 256)  590080      decoder_stage0_relu1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0_relu2 (Activatio (None, 48, 48, 256)  0           decoder_stage0_conv2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1_upsample (UpSamp (None, 96, 96, 256)  0           decoder_stage0_relu2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 96, 96, 384)  0           decoder_stage1_upsample[0][0]    \n",
      "                                                                 stage3_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1_conv1 (Conv2D)   (None, 96, 96, 128)  442496      concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1_relu1 (Activatio (None, 96, 96, 128)  0           decoder_stage1_conv1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1_conv2 (Conv2D)   (None, 96, 96, 128)  147584      decoder_stage1_relu1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1_relu2 (Activatio (None, 96, 96, 128)  0           decoder_stage1_conv2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2_upsample (UpSamp (None, 192, 192, 128 0           decoder_stage1_relu2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 192, 192, 192 0           decoder_stage2_upsample[0][0]    \n",
      "                                                                 stage2_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2_conv1 (Conv2D)   (None, 192, 192, 64) 110656      concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2_relu1 (Activatio (None, 192, 192, 64) 0           decoder_stage2_conv1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2_conv2 (Conv2D)   (None, 192, 192, 64) 36928       decoder_stage2_relu1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2_relu2 (Activatio (None, 192, 192, 64) 0           decoder_stage2_conv2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3_upsample (UpSamp (None, 384, 384, 64) 0           decoder_stage2_relu2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 384, 384, 128 0           decoder_stage3_upsample[0][0]    \n",
      "                                                                 relu0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3_conv1 (Conv2D)   (None, 384, 384, 32) 36896       concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3_relu1 (Activatio (None, 384, 384, 32) 0           decoder_stage3_conv1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3_conv2 (Conv2D)   (None, 384, 384, 32) 9248        decoder_stage3_relu1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3_relu2 (Activatio (None, 384, 384, 32) 0           decoder_stage3_conv2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage4_upsample (UpSamp (None, 768, 768, 32) 0           decoder_stage3_relu2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage4_conv1 (Conv2D)   (None, 768, 768, 16) 4624        decoder_stage4_upsample[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage4_relu1 (Activatio (None, 768, 768, 16) 0           decoder_stage4_conv1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage4_conv2 (Conv2D)   (None, 768, 768, 16) 2320        decoder_stage4_relu1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage4_relu2 (Activatio (None, 768, 768, 16) 0           decoder_stage4_conv2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "final_conv (Conv2D)             (None, 768, 768, 1)  145         decoder_stage4_relu2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "sigmoid (Activation)            (None, 768, 768, 1)  0           final_conv[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 24,453,178\n",
      "Trainable params: 24,437,812\n",
      "Non-trainable params: 15,366\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "seg_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.losses import binary_crossentropy\n",
    "from keras import backend as K\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred = K.cast(y_pred, 'float32')\n",
    "    y_pred_f = K.cast(K.greater(K.flatten(y_pred), 0.5), 'float32')\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = 2. * K.sum(intersection) / (K.sum(y_true_f) + K.sum(y_pred_f))\n",
    "    return score\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    return 1. - score\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
    "\n",
    "def bce_logdice_loss(y_true, y_pred):\n",
    "    return binary_crossentropy(y_true, y_pred) - K.log(1. - dice_loss(y_true, y_pred))\n",
    "\n",
    "def weighted_bce_loss(y_true, y_pred, weight):\n",
    "    epsilon = 1e-7\n",
    "    y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n",
    "    logit_y_pred = K.log(y_pred / (1. - y_pred))\n",
    "    loss = weight * (logit_y_pred * (1. - y_true) + \n",
    "                     K.log(1. + K.exp(-K.abs(logit_y_pred))) + K.maximum(-logit_y_pred, 0.))\n",
    "    return K.sum(loss) / K.sum(weight)\n",
    "\n",
    "def weighted_dice_loss(y_true, y_pred, weight):\n",
    "    smooth = 1.\n",
    "    w, m1, m2 = weight, y_true, y_pred\n",
    "    intersection = (m1 * m2)\n",
    "    score = (2. * K.sum(w * intersection) + smooth) / (K.sum(w * m1) + K.sum(w * m2) + smooth)\n",
    "    loss = 1. - K.sum(score)\n",
    "    return loss\n",
    "\n",
    "def weighted_bce_dice_loss(y_true, y_pred):\n",
    "    y_true = K.cast(y_true, 'float32')\n",
    "    y_pred = K.cast(y_pred, 'float32')\n",
    "    # if we want to get same size of output, kernel size must be odd\n",
    "    averaged_mask = K.pool2d(\n",
    "            y_true, pool_size=(50, 50), strides=(1, 1), padding='same', pool_mode='avg')\n",
    "    weight = K.ones_like(averaged_mask)\n",
    "    w0 = K.sum(weight)\n",
    "    weight = 5. * K.exp(-5. * K.abs(averaged_mask - 0.5))\n",
    "    w1 = K.sum(weight)\n",
    "    weight *= (w0 / w1)\n",
    "    loss = weighted_bce_loss(y_true, y_pred, weight) + dice_loss(y_true, y_pred)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import binary_crossentropy\n",
    "def dice_coef(y_true, y_pred, smooth=1):\n",
    "    intersection = K.sum(y_true * y_pred, axis=[1,2,3])\n",
    "    union = K.sum(y_true, axis=[1,2,3]) + K.sum(y_pred, axis=[1,2,3])\n",
    "    return K.mean( (2. * intersection + smooth) / (union + smooth), axis=0)\n",
    "def dice_p_bce(in_gt, in_pred):\n",
    "    return 1e-3*binary_crossentropy(in_gt, in_pred) - dice_coef(in_gt, in_pred)\n",
    "#def true_positive_rate(y_true, y_pred):\n",
    "#    return K.sum(K.flatten(y_true)*K.flatten(K.round(y_pred)))/K.sum(y_true)\n",
    "def true_positive_rate(y_true, y_pred):\n",
    "    return K.sum(K.flatten(y_true)*K.flatten(K.round(y_pred)))/(K.sum(y_true) + K.epsilon())\n",
    "#seg_model.compile(optimizer=Adam(1e-4, decay=1e-6), loss=dice_p_bce, metrics=[dice_coef, 'binary_accuracy', true_positive_rate])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "348"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\keras\\callbacks.py:1065: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "  warnings.warn('`epsilon` argument is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n",
    "weight_path=\"{}_weights.best.hdf5\".format('seg_model')\n",
    "\n",
    "checkpoint = ModelCheckpoint(weight_path, monitor='val_dice_coef', verbose=1, \n",
    "                             save_best_only=True, mode='max', save_weights_only = True)\n",
    "\n",
    "reduceLROnPlat = ReduceLROnPlateau(monitor='val_dice_coef', factor=0.5, \n",
    "                                   patience=3, \n",
    "                                   verbose=1, mode='max', epsilon=0.0001, cooldown=2, min_lr=1e-6)\n",
    "early = EarlyStopping(monitor=\"val_dice_coef\", \n",
    "                      mode=\"max\", \n",
    "                      patience=15) # probably needs to be more patient, but kaggle time is limited\n",
    "callbacks_list = [checkpoint, early, reduceLROnPlat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comiple model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_model.compile(optimizer=Adam(1e-5, decay=1e-6), loss=bce_logdice_loss, metrics=[dice_coef, 'binary_accuracy', true_positive_rate])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nweight_path=\"{}_weights.best.hdf5\".format(\\'seg_model\\')\\n\\nearly_stopping = EarlyStopping(patience=10, verbose=1)\\nmodel_checkpoint = ModelCheckpoint(weight_path, save_best_only=True, verbose=1)\\nreduce_lr = ReduceLROnPlateau(factor=0.1, patience=4, min_lr=0.00001, verbose=1)\\n'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "weight_path=\"{}_weights.best.hdf5\".format('seg_model')\n",
    "\n",
    "early_stopping = EarlyStopping(patience=10, verbose=1)\n",
    "model_checkpoint = ModelCheckpoint(weight_path, save_best_only=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(factor=0.1, patience=4, min_lr=0.00001, verbose=1)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      " 13/200 [>.............................] - ETA: 13:07:05 - loss: 5.9470 - dice_coef: 0.0056 - binary_accuracy: 0.0076 - true_positive_rate: 0.99 - ETA: 11:07:39 - loss: 5.3482 - dice_coef: 0.0117 - binary_accuracy: 0.0103 - true_positive_rate: 0.99 - ETA: 10:26:08 - loss: 5.5714 - dice_coef: 0.0095 - binary_accuracy: 0.0119 - true_positive_rate: 0.99 - ETA: 9:50:51 - loss: 5.9399 - dice_coef: 0.0075 - binary_accuracy: 0.0156 - true_positive_rate: 0.9923 - ETA: 9:24:35 - loss: 5.8259 - dice_coef: 0.0079 - binary_accuracy: 0.0219 - true_positive_rate: 0.992 - ETA: 9:08:18 - loss: 5.8839 - dice_coef: 0.0073 - binary_accuracy: 0.0370 - true_positive_rate: 0.993 - ETA: 9:08:02 - loss: 6.1128 - dice_coef: 0.0064 - binary_accuracy: 0.0561 - true_positive_rate: 0.992 - ETA: 9:03:27 - loss: 6.0046 - dice_coef: 0.0070 - binary_accuracy: 0.0721 - true_positive_rate: 0.984 - ETA: 8:58:06 - loss: 5.9790 - dice_coef: 0.0069 - binary_accuracy: 0.0913 - true_positive_rate: 0.981 - ETA: 8:53:41 - loss: 5.9026 - dice_coef: 0.0073 - binary_accuracy: 0.1134 - true_positive_rate: 0.976 - ETA: 8:47:22 - loss: 5.8890 - dice_coef: 0.0072 - binary_accuracy: 0.1431 - true_positive_rate: 0.969 - ETA: 8:49:10 - loss: 5.9264 - dice_coef: 0.0069 - binary_accuracy: 0.1696 - true_positive_rate: 0.956 - ETA: 8:46:31 - loss: 5.8395 - dice_coef: 0.0076 - binary_accuracy: 0.2027 - true_positive_rate: 0.9503"
     ]
    }
   ],
   "source": [
    "\n",
    "epochs = 15\n",
    "batch_size = 4\n",
    "\n",
    "step_count = min(MAX_TRAIN_STEPS, balanced_train_df.shape[0]//BATCH_SIZE)\n",
    "aug_gen = create_aug_gen(make_image_gen(balanced_train_df))\n",
    "loss_history = [seg_model.fit_generator(aug_gen,\n",
    "                            steps_per_epoch=step_count,\n",
    "                            validation_data=(valid_x, valid_y), \n",
    "                            epochs=5,\n",
    "                            callbacks=callbacks_list,shuffle=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_model.load_weights(weight_path)\n",
    "seg_model.save('seg_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot loss history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " epich = np.cumsum(np.concatenate(\n",
    "        [np.linspace(0.5, 1, len(mh.epoch)) for mh in loss_history]))\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(22, 10))\n",
    "    _ = ax1.plot(epich,\n",
    "                 np.concatenate([mh.history['loss'] for mh in loss_history]),\n",
    "                 'b-',\n",
    "                 epich, np.concatenate(\n",
    "            [mh.history['val_loss'] for mh in loss_history]), 'r-')\n",
    "    ax1.legend(['Training', 'Validation'])\n",
    "    ax1.set_title('Loss')\n",
    "    \n",
    "    _ = ax2.plot(epich, np.concatenate(\n",
    "        [mh.history['dice_coef'] for mh in loss_history]), 'b-',\n",
    "                     epich, np.concatenate(\n",
    "            [mh.history['val_dice_coef'] for mh in loss_history]),\n",
    "                     'r-')\n",
    "    ax2.legend(['Training', 'Validation'])\n",
    "    ax2.set_title('DICE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare Full Resolution Model\n",
    "#Here we account for the scaling so everything can happen in the model itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models, layers\n",
    "if IMG_SCALING is not None:\n",
    "    fullres_model = models.Sequential()\n",
    "    fullres_model.add(layers.AvgPool2D(IMG_SCALING, input_shape = (None, None, 3)))\n",
    "    fullres_model.add(seg_model)\n",
    "    fullres_model.add(layers.UpSampling2D(IMG_SCALING))\n",
    "else:\n",
    "    fullres_model = seg_model\n",
    "fullres_model.save('./fullres_model_net34.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
